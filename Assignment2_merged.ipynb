{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, copy\n",
    "from collections import defaultdict\n",
    "import numpy, re, math\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from string import punctuation\n",
    "from scipy import stats\n",
    "import pandas\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model, datasets\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"h1b_kaggle.csv\")\n",
    "data = data.set_index('Unnamed: 0')\n",
    "# Removing rows with NA in case_status\n",
    "data = data[pandas.notnull(data['CASE_STATUS'])]\n",
    "data = data.drop(data[data.CASE_STATUS == 'REJECTED'].index)\n",
    "data = data.drop(data[data.CASE_STATUS == 'INVALIDATED'].index)\n",
    "data = data.drop(data[data.CASE_STATUS == 'WITHDRAWN'].index)\n",
    "data = data.drop(data[data.CASE_STATUS == 'PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED'].index)\n",
    "\n",
    "# To keep rows which have employer names that are among the ~1200 most frequent\n",
    "threshold = 0.0001\n",
    "#for col in df:\n",
    "col = 'EMPLOYER_NAME'\n",
    "counts = data[col].value_counts(normalize=True)\n",
    "data = data.loc[data[col].isin(counts[counts > threshold].index), :]\n",
    "\n",
    "# Case_status = 1 for certified/certified-withdrawn, 0 for denied\n",
    "data['CASE_STATUS'] = data['CASE_STATUS'].map({'CERTIFIED': 1, 'DENIED': 0, 'CERTIFIED-WITHDRAWN': 2})\n",
    "data['CASE_STATUS'].replace(2,1, inplace=True)\n",
    "data['FULL_TIME_POSITION'] = data['FULL_TIME_POSITION'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Separating states and adding that as another column\n",
    "states = []\n",
    "for row in data.iterrows():\n",
    "    st = row[1]['WORKSITE'].split(',')[-1][1:]\n",
    "    states.append(st)\n",
    "s = pandas.Series(states)\n",
    "data['STATES'] = s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_map = {\n",
    "    'ALABAMA': 1,\n",
    "    'ALASKA': 2,\n",
    "    'ARIZONA': 3,\n",
    "    'ARKANSAS': 4,\n",
    "    'CALIFORNIA': 5,\n",
    "    'COLORADO': 6,\n",
    "    'CONNECTICUT': 7,\n",
    "    'DELAWARE': 8,\n",
    "    'DISTRICT OF COLUMBIA': 9,\n",
    "    'FLORIDA': 10,\n",
    "    'GEORGIA': 11,\n",
    "    'HAWAII': 12,\n",
    "    'IDAHO': 13,\n",
    "    'ILLINOIS': 14,\n",
    "    'INDIANA': 15,\n",
    "    'IOWA': 16,\n",
    "    'KANSAS': 17,\n",
    "    'KENTUCKY': 18,\n",
    "    'LOUISIANA': 19,\n",
    "    'MAINE': 20,\n",
    "    'MARYLAND': 21,\n",
    "    'MASSACHUSETTS': 22,\n",
    "    'MICHIGAN': 23,\n",
    "    'MINNESOTA': 24,\n",
    "    'MISSISSIPPI': 25,\n",
    "    'MISSOURI': 26,\n",
    "    'MONTANA': 27,\n",
    "    'NEBRASKA': 28,\n",
    "    'NEVADA': 29,\n",
    "    'NEW HAMPSHIRE': 30,\n",
    "    'NEW JERSEY': 31,\n",
    "    'NEW MEXICO': 32,\n",
    "    'NEW YORK': 33,\n",
    "    'NORTH CAROLINA': 34,\n",
    "    'NORTH DAKOTA': 35,\n",
    "    'OHIO': 36,\n",
    "    'OKLAHOMA': 37,\n",
    "    'OREGON': 38,\n",
    "    'PENNSYLVANIA': 39,\n",
    "    'PUERTO RICO': 40,\n",
    "    'RHODE ISLAND': 41,\n",
    "    'SOUTH CAROLINA': 42,\n",
    "    'SOUTH DAKOTA': 43,\n",
    "    'TENNESSEE': 44,\n",
    "    'TEXAS': 45,\n",
    "    'UTAH': 46,\n",
    "    'VERMONT': 47,\n",
    "    'VIRGINIA': 48,\n",
    "    'WASHINGTON': 49,\n",
    "    'WEST VIRGINIA': 50,\n",
    "    'WISCONSIN': 51,\n",
    "    'WYOMING': 52}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*(1+6+len(state_map)+len(employers_id))\n",
    "    feat[0] = 1\n",
    "    feat[int(datum['YEAR']) - 2010] = 1\n",
    "    feat[state_map[datum['STATES']]+6] = 1\n",
    "    feat[employers_id[datum['EMPLOYER_NAME']]+len(state_map)+6] = 1\n",
    "    return feat\n",
    "\n",
    "emp_list = data.EMPLOYER_NAME.unique().tolist()\n",
    "employers_id = dict(zip(emp_list, range(len(emp_list))))\n",
    "\n",
    "X_train = [feature(d[1]) for d in data.loc[:500000,:].iterrows() if d[1]['STATES'] != 'NA']\n",
    "y_train = [d[1]['CASE_STATUS'] for d in data.loc[:500000,:].iterrows() if d[1]['STATES'] != 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validation =  [feature(d[1]) for d in data.loc[500000:1000000,:].iterrows() if d[1]['STATES'] != 'NA']\n",
    "y_validation =  [d[1]['CASE_STATUS'] for d in data.loc[500000:1000000,:].iterrows() if d[1]['STATES'] != 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  [feature(d[1]) for d in data.loc[1000000:,:].iterrows() if d[1]['STATES'] != 'NA']\n",
    "y_test =  [d[1]['CASE_STATUS'] for d in data.loc[1000000:,:].iterrows() if d[1]['STATES'] != 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(C=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.983751667148\nFPR = 0.995033998014\nFNR = 0.00289457774813\n"
     ]
    }
   ],
   "source": [
    "classifierStats(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifierStats(pred):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(pred)):\n",
    "        if y_test[i] == 1:\n",
    "            if pred[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if pred[i] == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    print(\"Accuracy = \" + str(1.0*(tp + tn)/(tn+fp+fn+tp)))\n",
    "    print(\"FPR = \" + str(1.0*fp/(tn+fp)))\n",
    "    print(\"FNR = \" + str(1.0*fn/(tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.986540444991\nFPR = 1.0\nFNR = 0.0\n"
     ]
    }
   ],
   "source": [
    "#Baseline 1 : ZeroR\n",
    "y_consolidated = y_train + y_validation \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def Most_Common(y_consolidated):\n",
    "    data = Counter(y_consolidated)\n",
    "    return data.most_common(1)[0][0]\n",
    "\n",
    "pred_baselise1 = [Most_Common(y_consolidated)] * len(y_test)\n",
    "\n",
    "#Accuracy & FNR & FPR\n",
    "classifierStats(pred_baselise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.979645623665\nFPR = 0.993047597219\nFNR = 0.00708374158311\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#Baseline 2 : Biased Coin Toss\n",
    "sum = numpy.sum(y_consolidated)\n",
    "sum = sum*1.0/len(y_consolidated)\n",
    "#Accuracy\n",
    "pred_baselise2 = [ (random.random() < sum) for x in range(len(y_test)) ]\n",
    "#FNR & FPR\n",
    "classifierStats(pred_baselise2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}